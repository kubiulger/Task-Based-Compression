{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperprior_Joint.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install compressai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cp5ycm3-F3M",
        "outputId": "79055482-3950-4d85-84ac-712905938440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting compressai\n",
            "  Downloading compressai-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[K     |████████████████████████████████| 295 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from compressai) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from compressai) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from compressai) (1.11.0+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from compressai) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from compressai) (0.12.0+cu113)\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.1->compressai) (4.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->compressai) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->compressai) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->compressai) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->compressai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->compressai) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->compressai) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->compressai) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->compressai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->compressai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->compressai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->compressai) (2021.10.8)\n",
            "Installing collected packages: pytorch-msssim, compressai\n",
            "Successfully installed compressai-1.2.0 pytorch-msssim-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "from compressai.datasets import ImageFolder\n",
        "from compressai.zoo import image_models\n",
        "import compressai"
      ],
      "metadata": {
        "id": "5p_DL1Ab9Qsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from compressai.zoo import (bmshj2018_factorized, bmshj2018_hyperprior, mbt2018_mean, mbt2018, cheng2020_anchor)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "metric = 'mse'  # only pre-trained model for mse are available for now\n",
        "quality = 1     # lower quality -> lower bit-rate (use lower quality to clearly see visual differences in the notebook)\n",
        "networks = {\n",
        "    'bmshj2018-factorized': bmshj2018_factorized(quality=quality, pretrained=True).eval().to(device),\n",
        "    'bmshj2018-hyperprior': bmshj2018_hyperprior(quality=quality, pretrained=True).eval().to(device),\n",
        "    'mbt2018-mean': mbt2018_mean(quality=quality, pretrained=True).eval().to(device),\n",
        "    'mbt2018': mbt2018(quality=quality, pretrained=True).eval().to(device),\n",
        "    'cheng2020-anchor': cheng2020_anchor(quality=quality, pretrained=True).eval().to(device),\n",
        "}\n",
        "\n",
        "net = networks['bmshj2018-hyperprior']"
      ],
      "metadata": {
        "id": "Oe6rH0dCF__N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.aux_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrsF-JlEKuMY",
        "outputId": "dba4c193-c1cd-45cd-db28-05faa77e3243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(172.0104, device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXQB6rGC_R7S",
        "outputId": "f167fb37-ae01-48ef-c82e-39a06d72f3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.chdir(r'/content/MyDrive/MyDrive/DL_Project_HP')"
      ],
      "metadata": {
        "id": "WSY16bW3_Zx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Classes"
      ],
      "metadata": {
        "id": "7TFzATzt9Yb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RateDistortionLoss(nn.Module):\n",
        "    \"\"\"Custom rate distortion loss with a Lagrangian parameter.\"\"\"\n",
        "\n",
        "    def __init__(self, lmbda=1e-2):\n",
        "        super().__init__()\n",
        "        self.crossEntropy = nn.CrossEntropyLoss()\n",
        "        self.lmbda = lmbda\n",
        "\n",
        "    def forward(self, output, target, preds, labels):\n",
        "        N, _, H, W = target.size()\n",
        "        out = {}\n",
        "        num_pixels = N * H * W\n",
        "\n",
        "        out[\"bpp_loss\"] = sum(\n",
        "            (torch.log(likelihoods).sum() / (-math.log(2) * num_pixels))\n",
        "            for likelihoods in output[\"likelihoods\"].values()\n",
        "        )\n",
        "        out['log_loss'] = self.crossEntropy(preds, labels)\n",
        "        out[\"loss\"] = self.lmbda * out[\"log_loss\"] + out[\"bpp_loss\"]\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Compute running average.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "class CustomDataParallel(nn.DataParallel):\n",
        "    \"\"\"Custom DataParallel to access the module methods.\"\"\"\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        try:\n",
        "            return super().__getattr__(key)\n",
        "        except AttributeError:\n",
        "            return getattr(self.module, key)\n",
        "\n",
        "\n",
        "def configure_optimizers(net, args):\n",
        "    \"\"\"Separate parameters for the main optimizer and the auxiliary optimizer.\n",
        "    Return two optimizers\"\"\"\n",
        "\n",
        "    parameters = {\n",
        "        n\n",
        "        for n, p in net.named_parameters()\n",
        "        if not n.endswith(\".quantiles\") and p.requires_grad\n",
        "    }\n",
        "    aux_parameters = {\n",
        "        n\n",
        "        for n, p in net.named_parameters()\n",
        "        if n.endswith(\".quantiles\") and p.requires_grad\n",
        "    }\n",
        "\n",
        "    # Make sure we don't have an intersection of parameters\n",
        "    params_dict = dict(net.named_parameters())\n",
        "    inter_params = parameters & aux_parameters\n",
        "    union_params = parameters | aux_parameters\n",
        "\n",
        "    assert len(inter_params) == 0\n",
        "    assert len(union_params) - len(params_dict.keys()) == 0\n",
        "\n",
        "    optimizer = optim.Adam(\n",
        "        (params_dict[n] for n in sorted(parameters)),\n",
        "        lr=args.learning_rate\n",
        "    )\n",
        "    aux_optimizer = optim.Adam(\n",
        "        (params_dict[n] for n in sorted(aux_parameters)),\n",
        "        lr=args.aux_learning_rate,\n",
        "    )\n",
        "    return optimizer, aux_optimizer"
      ],
      "metadata": {
        "id": "0GA6VAFR9aAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Test Epochs"
      ],
      "metadata": {
        "id": "fDOq8V1t9bFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    model, criterion, train_dataloader, optimizer, aux_optimizer, epoch, clip_max_norm\n",
        "):\n",
        "    model.train()\n",
        "    device = next(model.parameters()).device\n",
        "    train_acc = 0\n",
        "\n",
        "    for i, d in enumerate(train_dataloader):\n",
        "        images = d[0].to(device)\n",
        "        labels = d[1].to(device)\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        aux_optimizer.zero_grad()\n",
        "\n",
        "        if clip_max_norm > 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_max_norm)\n",
        "\n",
        "        out_net = model(images)\n",
        "        preds = out_net['y_hat']\n",
        "        pred_labels = out_net['y_hat'].argmax(dim=1)\n",
        "        train_acc += torch.sum(labels == pred_labels).item()\n",
        "        out_criterion = criterion(out_net, images, preds, labels)\n",
        "        out_criterion[\"loss\"].backward()\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        aux_loss = model.aux_loss()\n",
        "        aux_loss.backward()\n",
        "        aux_optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(\n",
        "                f\"Train epoch {epoch}: [\"\n",
        "                f\"{i*len(images)}/{len(train_dataloader.dataset)}\"\n",
        "                f\" ({100. * i / len(train_dataloader):.0f}%)]\"\n",
        "\n",
        "                f'\\tLoss: {out_criterion[\"loss\"].item():.3f} |'\n",
        "                f'\\tBpp loss: {out_criterion[\"bpp_loss\"].item():.2f} |'\n",
        "                f'\\tLog loss: {out_criterion[\"log_loss\"].item():.2f} |'\n",
        "                f\"\\tAux loss: {aux_loss.item():.2f}\"\n",
        "            )\n",
        "    train_acc = train_acc/500\n",
        "    print(f'\\nTrain epoch {epoch}: \\tAcc: {train_acc:.3f} |')\n",
        "\n",
        "\n",
        "def test_epoch(epoch, test_dataloader, model, criterion):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    loss = AverageMeter()\n",
        "    bpp_loss = AverageMeter()\n",
        "    mse_loss = AverageMeter()\n",
        "    aux_loss = AverageMeter()\n",
        "    test_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for d in test_dataloader:\n",
        "            images = d[0].to(device)\n",
        "            labels = d[1].to(device)\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            out_net = model(images)\n",
        "            preds = out_net['y_hat']\n",
        "            pred_labels = out_net['y_hat'].argmax(dim=1)\n",
        "            test_acc += torch.sum(labels == pred_labels).item()\n",
        "\n",
        "            out_criterion = criterion(out_net, images, preds, labels)\n",
        "\n",
        "            aux_loss.update(model.aux_loss())\n",
        "            bpp_loss.update(out_criterion[\"bpp_loss\"])\n",
        "            loss.update(out_criterion[\"loss\"])\n",
        "    test_acc = test_acc / 100\n",
        "    print(\n",
        "        f\"Test epoch {epoch}: Average losses:\"\n",
        "        f'\\tAcc: {test_acc:.3f} |'\n",
        "        f\"\\tLoss: {loss.avg:.3f} |\"\n",
        "        f\"\\tBpp loss: {bpp_loss.avg:.2f} |\"\n",
        "        f'\\tLog loss: {out_criterion[\"log_loss\"].item():.2f} |'\n",
        "        f\"\\tAux loss: {aux_loss.avg:.2f}\\n\"\n",
        "    )\n",
        "\n",
        "    return loss.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, epoch, is_best, filename, best_filename):\n",
        "    torch.save(state, str(epoch)+filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(str(epoch)+ filename, best_filename)\n"
      ],
      "metadata": {
        "id": "tsS_geUH9hpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "0XaiYtqC9nLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHYmZp2I9DVu"
      },
      "outputs": [],
      "source": [
        "def main(model, num_workers, batch_size, cuda, epoch, patch_size, learning_rate, lmbda):\n",
        "    # args = parse_args(argv)\n",
        "\n",
        "    # if args.seed is not None:\n",
        "    #     torch.manual_seed(args.seed)\n",
        "    #     random.seed(args.seed)\n",
        "\n",
        "    class arguments:\n",
        "      def __init__(self, model, num_workers, batch_size, cuda, epoch, patch_size, learning_rate, lmbda):\n",
        "        self.model = model\n",
        "        self.num_workers = num_workers\n",
        "        self.batch_size = batch_size\n",
        "        self.test_batch_size = 100\n",
        "        self.cuda = cuda\n",
        "        self.epochs = epoch\n",
        "        self.patch_size = patch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.aux_learning_rate = learning_rate\n",
        "        self.lmbda = lmbda\n",
        "        self.save = True\n",
        "        self.seed = False\n",
        "        self.clip_max_norm = 1.0\n",
        "        self.checkpoint = False\n",
        "\n",
        "\n",
        "    tr_mean = np.asarray([0.4914, 0.4822, 0.4465])\n",
        "    tr_std = np.asarray([0.247, 0.243, 0.261])\n",
        "\n",
        "    args = arguments(model, num_workers, batch_size, cuda, epoch, patch_size, learning_rate, lmbda)\n",
        "\n",
        "    train_transforms = transforms.Compose(\n",
        "        [transforms.Resize((64,64)), transforms.ToTensor(), transforms.RandomCrop(args.patch_size), torchvision.transforms.Normalize(tr_mean, tr_std)]\n",
        "    )\n",
        "\n",
        "    test_transforms = transforms.Compose(\n",
        "        [transforms.Resize((64,64)), transforms.ToTensor(), transforms.CenterCrop(args.patch_size), torchvision.transforms.Normalize(tr_mean, tr_std)]\n",
        "    )\n",
        "\n",
        "    # train_dataset = ImageFolder(args.dataset, split=\"train\", transform=train_transforms)\n",
        "    # test_dataset = ImageFolder(args.dataset, split=\"test\", transform=test_transforms)\n",
        "\n",
        "    train_dataset = torchvision.datasets.CIFAR10('./CIFAR-10/',train=True,download=True, transform=train_transforms)\n",
        "    test_dataset = torchvision.datasets.CIFAR10('./CIFAR-10/',train=False,download=True, transform=test_transforms)\n",
        "\n",
        "    device = \"cuda\" if args.cuda and torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "        shuffle=True,\n",
        "        pin_memory=(device == \"cuda\"),\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=args.test_batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "        shuffle=False,\n",
        "        pin_memory=(device == \"cuda\"),\n",
        "    )\n",
        "\n",
        "\n",
        "    ##########################################################################\n",
        "    net = model\n",
        "    resnet = torchvision.models.resnet18(pretrained = True)\n",
        "    resnet.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self, resnet, net):\n",
        "            super(Net, self).__init__()\n",
        "\n",
        "            self.g_a = net.g_a\n",
        "            self.h_a = net.h_a\n",
        "            self.g_s = net.g_s\n",
        "            self.h_s = net.h_s\n",
        "            self.entropy_bottleneck = net.entropy_bottleneck\n",
        "            self.gaussian_conditional = net.gaussian_conditional\n",
        "            self.res = resnet\n",
        "\n",
        "        def forward(self, x):\n",
        "            y = self.g_a(x)\n",
        "            z = self.h_a(torch.abs(y))\n",
        "            z_hat, z_likelihoods = self.entropy_bottleneck(z)\n",
        "            scales_hat = self.h_s(z_hat)\n",
        "            y_hat, y_likelihoods = self.gaussian_conditional(y, scales_hat)\n",
        "            x_hat = self.g_s(y_hat)\n",
        "            l_hat = self.res(x_hat)\n",
        "\n",
        "            return {\n",
        "                \"x_hat\": x_hat,\n",
        "                \"y_hat\": l_hat,\n",
        "                \"likelihoods\": {\"y\": y_likelihoods, \"z\": z_likelihoods},\n",
        "            }\n",
        "\n",
        "\n",
        "    net = Net(resnet, net)\n",
        "    net.aux_loss = model.aux_loss\n",
        "    net = net.to(device)\n",
        "    ##########################################################################\n",
        "\n",
        "\n",
        "    if args.cuda and torch.cuda.device_count() > 1:\n",
        "        net = CustomDataParallel(net)\n",
        "\n",
        "    optimizer, aux_optimizer = configure_optimizers(net, args)\n",
        "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\",factor=0.5)\n",
        "    criterion = RateDistortionLoss(lmbda=args.lmbda)\n",
        "\n",
        "    filename = str(args.lmbda) + '_check.pth.tar'\n",
        "    best_filename = 'best' + filename\n",
        "\n",
        "    last_epoch = 0\n",
        "    if args.checkpoint:  # load from previous checkpoint\n",
        "        print(\"Loading\", args.checkpoint)\n",
        "        checkpoint = torch.load(args.checkpoint, map_location=device)\n",
        "        last_epoch = checkpoint[\"epoch\"] + 1\n",
        "        net.load_state_dict(checkpoint[\"state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "        aux_optimizer.load_state_dict(checkpoint[\"aux_optimizer\"])\n",
        "        lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    for epoch in range(last_epoch, args.epochs):\n",
        "        T11 = time.time()\n",
        "\n",
        "        print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
        "        train_one_epoch(\n",
        "            net,\n",
        "            criterion,\n",
        "            train_dataloader,\n",
        "            optimizer,\n",
        "            aux_optimizer,\n",
        "            epoch,\n",
        "            args.clip_max_norm,\n",
        "        )\n",
        "        loss = test_epoch(epoch, test_dataloader, net, criterion)\n",
        "        lr_scheduler.step(loss)\n",
        "        T22 = time.time()\n",
        "        print(f\"Time: {T22-T11:.4f}\")\n",
        "        is_best = loss < best_loss\n",
        "        best_loss = min(loss, best_loss)\n",
        "\n",
        "        if args.save:\n",
        "            save_checkpoint(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"state_dict\": net.state_dict(),\n",
        "                    \"loss\": loss,\n",
        "                    \"optimizer\": optimizer.state_dict(),\n",
        "                    \"aux_optimizer\": aux_optimizer.state_dict(),\n",
        "                    \"lr_scheduler\": lr_scheduler.state_dict(),\n",
        "                },\n",
        "                epoch,\n",
        "                is_best,\n",
        "                filename,\n",
        "                best_filename,\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lmbda = np.asarray([0.01, 0.015, 0.020, 0.05, 0.125, 0.5, 1, 5]).astype(float)*0.01\n",
        "\n",
        "for lmb in lmbda:\n",
        "  net_out = main(net, 2, 64, 1, 200, 64, 0.001, lmb)"
      ],
      "metadata": {
        "id": "gxftyVzj9nbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}